{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b003554",
   "metadata": {},
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Dara Loading and Preprocessing</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Conclustions</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0eb7e0",
   "metadata": {},
   "source": [
    "# 01 - ***ML for Texts*** - Project for WikiShop\n",
    "\n",
    "[Nice reading about BERT](https://docs.deeppavlov.ai/en/master/features/models/bert.html)\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers) is a Transformer pre-trained on masked language model and next sentence prediction tasks. This approach showed state-of-the-art results on a wide range of NLP tasks in English."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dece3c66",
   "metadata": {},
   "source": [
    "### Project Goal\n",
    "The project goal is a binary text classification using BERT model.\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузить и подготовить данные.\n",
    "2. Обучить разные модели. \n",
    "3. Сделать выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "654e9b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/local/opt/python@3.10/bin/python3.10 -m pip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9364e85c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Operation not permitted\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/pip/__main__.py\", line 9, in <module>\n",
      "    if sys.path[0] in (\"\", os.getcwd()):\n",
      "PermissionError: [Errno 1] Operation not permitted\n",
      "shell-init: error retrieving current directory: getcwd: cannot access parent directories: Operation not permitted\n",
      "2022-11-30 20:54:17.459138: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 187, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 146, in _get_module_details\n",
      "    return _get_module_details(pkg_main_name, error)\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 110, in _get_module_details\n",
      "    __import__(pkg_name)\n",
      "  File \"/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/spacy/__init__.py\", line 15, in <module>\n",
      "    from .cli.info import info  # noqa: F401\n",
      "  File \"/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/spacy/cli/__init__.py\", line 24, in <module>\n",
      "    from .project.assets import project_assets  # noqa: F401\n",
      "  File \"/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/spacy/cli/project/assets.py\", line 26, in <module>\n",
      "    project_dir: Path = Arg(Path.cwd(), help=\"Path to cloned project. Defaults to current working directory.\", exists=True, file_okay=False),\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/pathlib.py\", line 993, in cwd\n",
      "    return cls(cls._accessor.getcwd())\n",
      "PermissionError: [Errno 1] Operation not permitted\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install spacy -q\n",
    "!{sys.executable} -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7105cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import spacy\n",
    "from tqdm import notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score,make_scorer\n",
    "from catboost import CatBoostClassifier\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e4141b",
   "metadata": {},
   "source": [
    "## 1 Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e57dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/yuliabezginova/PycharmProjects/00_files-for_NLP/toxic_comments.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0c5bcfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c11acab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a1d2240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверка на пропуски в таргете\n",
    "data['toxic'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57e07c7",
   "metadata": {},
   "source": [
    "### 1.1 Работаем со стоп-словами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "958e3a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yuliabezginova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674949d",
   "metadata": {},
   "source": [
    "### 1.3 Переведём тексты в стандартный для Python формат: кодировку Unicode U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "321cd929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Изменим кодировку методом astype():\n",
    "corpus = data['text'].values.astype('U')\n",
    "# corpus_train = X_train.values.astype('U')\n",
    "# corpus_test = X_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c24893",
   "metadata": {},
   "source": [
    "### 1.4 Создадим функцию для лемматизации и очистки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a7e9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    m = Mystem()\n",
    "    m = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    # объединим элементы в одну строку пробелом или без него\n",
    "    lem = ' '.join(m.split())\n",
    "    return lem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048384d6",
   "metadata": {},
   "source": [
    "#### Протестируем работу функции лемматизации и очистки текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aec7381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: you are a stupid fuck \n",
      "\n",
      "and your mother's cunt stinks\n",
      "Очищенный и лемматизированный текст: you are a stupid fuck and your mother s cunt stinks\n"
     ]
    }
   ],
   "source": [
    "print(\"Исходный текст:\", corpus[181])\n",
    "print(\"Очищенный и лемматизированный текст:\", lemmatize(corpus[181]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ad650",
   "metadata": {},
   "source": [
    "#### Применим функцию для лемматизации и очистки текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "134123ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lem_text'] = data.text.apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d16d8041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  D'aww! He matches this background colour I'm s...      0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                            lem_text  \n",
       "0  Explanation Why the edits made under my userna...  \n",
       "1  D aww He matches this background colour I m se...  \n",
       "2  Hey man I m really not trying to edit war It s...  \n",
       "3  More I can t make any real suggestions on impr...  \n",
       "4  You sir are my hero Any chance you remember wh...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffe278f",
   "metadata": {},
   "source": [
    "### 1.5 Делим данные на тестовую и обучающую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c6140f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns='toxic', axis=1)\n",
    "target = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1755abcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b193e817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5585b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяю на обучающую и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8087464b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features sample size: 127433\n",
      "Train target sample size: 127433\n",
      "\n",
      "Test features sample size: 31859\n",
      "Test target sample size: 31859\n",
      "\n",
      "Test sample, %: 20.0\n"
     ]
    }
   ],
   "source": [
    "print('Train features sample size:', X_train.shape[0])\n",
    "print('Train target sample size:', y_train.shape[0])\n",
    "print()\n",
    "print('Test features sample size:', X_test.shape[0])\n",
    "print('Test target sample size:', y_test.shape[0])\n",
    "print()\n",
    "print('Test sample, %:', round(X_test.shape[0] / (X_test.shape[0] + X_train.shape[0]) * 100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9fd71d",
   "metadata": {},
   "source": [
    "### ВЫВОД: Исходные данные разделены на тестовые и обучающие, выделены признаки и таргетные значения. Дальнейшие преобразования текста будем производить только с признаками (текстом).\n",
    "\n",
    "Применим модель \"мешка слов\" к набору данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b51041",
   "metadata": {},
   "source": [
    "### 1.6 Модель «мешка слов» реализована в классе CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687fcf09",
   "metadata": {},
   "source": [
    "Мы импортируем класс CountVectorizer, создам экземпляр класса и подгоняем модель к нашим данным для анализа тональности твитов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4009b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0daa4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаю Tf-idf для обучающей\n",
    "X_train_vect = vect.fit_transform(X_train.lem_text)\n",
    "\n",
    "# Считаю Tf-idf для тестовой\n",
    "X_test_vect = vect.transform(X_test.lem_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4be7f4f",
   "metadata": {},
   "source": [
    "Перед тем как мы пытаемся улучшить выделение признаков, давайте измерим качество модели, построив классификатор. \n",
    "\n",
    "У нас есть обучающие метки, хранящиеся в y_train и обучающие данные, представленные в виде «мешка слов» X_train, таким образом, мы можем обучить классификатор по этим данным. \n",
    "\n",
    "Как правило, для подобных высокоразмерных разреженных данных лучше всего работают линейные модели типа LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f30e9b",
   "metadata": {},
   "source": [
    "### 1.7 Масштабирование признаков с помощью TF-IDF\n",
    "\n",
    "Следующий подход вместо исключения несущественных признаков пытается масштабировать признаки в зависимости от степени их информативности. Одним из наиболее распространенных способов такого масштабирования является метод частота термина-обратная частота документа (term frequency-inverse document frequency, tf-idf). \n",
    "\n",
    "**Идея этого метода заключается в том, чтобы присвоить большой вес термину, который часто встречается в конкретном документе, но при этом редко встречается в остальных документах корпуса. Если слово часто появляется в конкретном документе, но при этом редко встречается в остальных документах, оно, вероятно, будет описывать содержимое этого документа лучше.**\n",
    "\n",
    "Мешок слов учитывает частоту употребления слов. Посмотрим, как часто уникальное слово встречается во всём корпусе и в отдельном его тексте.\n",
    "\n",
    "Оценка важности слова определяется величиной TF-IDF (от англ. term frequency, «частота терма, или слова»; inverse document frequency, «обратная частота документа, или текста»). То есть TF отвечает за количество упоминаний слова в отдельном тексте, а IDF отражает частоту его употребления во всём корпусе.\n",
    "\n",
    "#### TFIDF = TF * IDF\n",
    "\n",
    "IDF нужна в формуле, чтобы уменьшить вес слов, наиболее\n",
    "распространённых в любом другом тексте заданного корпуса.\n",
    "IDF зависит от общего числа текстов в корпусе (D) и количества\n",
    "текстов, в которых это слово встречается (d).\n",
    "\n",
    "Большая величина TF-IDF говорит об уникальности слова в тексте\n",
    "по отношению к корпусу. Чем чаще оно встречается в конкретном\n",
    "тексте и реже в остальных, тем выше значение TF-IDF.\n",
    "\n",
    "**Если данные разделены на обучающую и тестовую выборки,\n",
    "функцию fit() запустим только на обучающей. Иначе тестирование\n",
    "будет нечестным: в модели будут учтены частоты слов из тестовой\n",
    "выборки.**\n",
    "\n",
    "Сначала переведем выборки X_train, X_test в векторный вид.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02f86d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c78b5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считаю Tf-idf для обучающей\n",
    "tf_idf_X_train = count_tf_idf.fit_transform(X_train['lem_text'])\n",
    "\n",
    "# Считаю Tf-idf для тестовой\n",
    "tf_idf_X_test = count_tf_idf.transform(X_test['lem_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5748667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы TF-IDF X_train: (127433, 147485)\n",
      "Размер матрицы TF-IDF X_test: (31859, 147485)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы TF-IDF X_train:\", tf_idf_X_train.shape)\n",
    "print(\"Размер матрицы TF-IDF X_test:\", tf_idf_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631cab78",
   "metadata": {},
   "source": [
    "### ВЫВОД: Данные очищены от странных букв и знаков, знаки пунктуации и стоп-слова удалены, данные разделены на тестовую и обучающую выборки, в каждой из которой выделены признаки и целевое значение. Выборки признаков приведены к векторному виду и готовы к обучению."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1703465",
   "metadata": {},
   "source": [
    "## 2 Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9382ded",
   "metadata": {},
   "source": [
    "### 2.1 Logistic Regression с использованием перекрестной проверки для модели «мешка слов» в классе CountVectorizer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a59c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19d3047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'C': [0.01, 0.1, 1, 2, 10, 100], \n",
    "     'penalty': ['l1', 'l2']}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1994f98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.93058313        nan 0.94952641        nan 0.95585915\n",
      "        nan 0.95599255        nan 0.9548547         nan 0.95270455]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=5), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: [0.01, 0.1, 1, 2, 10, 100],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}],\n",
       "             verbose=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=5), n_jobs=-1,\n",
       "             param_grid=[{&#x27;C&#x27;: [0.01, 0.1, 1, 2, 10, 100],\n",
       "                          &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]}],\n",
       "             verbose=False)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(random_state=5), n_jobs=-1,\n",
       "             param_grid=[{'C': [0.01, 0.1, 1, 2, 10, 100],\n",
       "                          'penalty': ['l1', 'l2']}],\n",
       "             verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_grid = GridSearchCV(logreg, \n",
    "                           param_grid, \n",
    "                           cv=3, \n",
    "                           verbose=False, \n",
    "                           n_jobs=-1)\n",
    "\n",
    "logreg_grid.fit(X_train_vect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38b4f939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение перекрестной проверки: 0.96\n",
      "Наилучшие параметры:  {'C': 2, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Наилучшее значение перекрестной проверки: {:.2f}\".format(logreg_grid.best_score_))\n",
    "print(\"Наилучшие параметры: \", logreg_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f96772",
   "metadata": {},
   "source": [
    "Теперь мы можем оценить на тестовом наборе обобщающую способность при использовании данной настройки параметра:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f49a4232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильность на тестовом наборе: 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Правильность на тестовом наборе: {:.2f}\".format(logreg_grid.score(X_test_vect, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5daf7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vect = logreg_grid.predict(tf_idf_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2e5e8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28565,  2220],\n",
       "       [    2,  1072]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred_vect, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f36a3c4",
   "metadata": {},
   "source": [
    "### 2.2 Logistic Regression с использованием решетчатого поиска для модели «мешка слов» в классе TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e022641",
   "metadata": {},
   "source": [
    "Поскольку tf-idf фактически использует статистические свойства\n",
    "обучающих данных, мы воспользуемся конвейером, чтобы убедиться в достоверности результатов решетчатого поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5e60a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2b07c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшее значение перекрестной проверки: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/3.4.8/libexec/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "grid = GridSearchCV(logreg, param_grid, cv=3)\n",
    "\n",
    "grid.fit(tf_idf_X_train, y_train)\n",
    "\n",
    "print(\"Наилучшее значение перекрестной проверки: {:.2f}\".format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e101a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tfidf = grid.predict(tf_idf_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1273efe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28295,  1027],\n",
       "       [  272,  2265]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred_tfidf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7556bde5",
   "metadata": {},
   "source": [
    "### 2.3 CatBoost в модели \"мешка слова\" в классе TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb23471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5939473\ttotal: 3.42s\tremaining: 2m 47s\n",
      "1:\tlearn: 0.5154453\ttotal: 4.94s\tremaining: 1m 58s\n",
      "2:\tlearn: 0.4532370\ttotal: 6.17s\tremaining: 1m 36s\n",
      "3:\tlearn: 0.4068591\ttotal: 7.6s\tremaining: 1m 27s\n",
      "4:\tlearn: 0.3720388\ttotal: 8.98s\tremaining: 1m 20s\n",
      "5:\tlearn: 0.3437147\ttotal: 10.2s\tremaining: 1m 14s\n",
      "6:\tlearn: 0.3206467\ttotal: 11.6s\tremaining: 1m 11s\n",
      "7:\tlearn: 0.3029510\ttotal: 12.7s\tremaining: 1m 6s\n",
      "8:\tlearn: 0.2886673\ttotal: 14s\tremaining: 1m 3s\n",
      "9:\tlearn: 0.2760725\ttotal: 15.3s\tremaining: 1m 1s\n",
      "10:\tlearn: 0.2669043\ttotal: 16.5s\tremaining: 58.5s\n",
      "11:\tlearn: 0.2594292\ttotal: 17.7s\tremaining: 56.2s\n",
      "12:\tlearn: 0.2533731\ttotal: 19.1s\tremaining: 54.3s\n",
      "13:\tlearn: 0.2484205\ttotal: 20.3s\tremaining: 52.3s\n",
      "14:\tlearn: 0.2440143\ttotal: 21.9s\tremaining: 51s\n",
      "15:\tlearn: 0.2400490\ttotal: 23.2s\tremaining: 49.2s\n",
      "16:\tlearn: 0.2370516\ttotal: 24.4s\tremaining: 47.4s\n",
      "17:\tlearn: 0.2336507\ttotal: 25.8s\tremaining: 45.8s\n",
      "18:\tlearn: 0.2309671\ttotal: 26.9s\tremaining: 44s\n",
      "19:\tlearn: 0.2285956\ttotal: 28.1s\tremaining: 42.2s\n",
      "20:\tlearn: 0.2265276\ttotal: 29.3s\tremaining: 40.5s\n",
      "21:\tlearn: 0.2242619\ttotal: 30.7s\tremaining: 39s\n",
      "22:\tlearn: 0.2224625\ttotal: 31.9s\tremaining: 37.5s\n",
      "23:\tlearn: 0.2201001\ttotal: 33.1s\tremaining: 35.9s\n",
      "24:\tlearn: 0.2187001\ttotal: 34.3s\tremaining: 34.3s\n",
      "25:\tlearn: 0.2173214\ttotal: 35.4s\tremaining: 32.7s\n",
      "26:\tlearn: 0.2160470\ttotal: 36.6s\tremaining: 31.2s\n",
      "27:\tlearn: 0.2147360\ttotal: 37.7s\tremaining: 29.6s\n",
      "28:\tlearn: 0.2133459\ttotal: 39s\tremaining: 28.3s\n",
      "29:\tlearn: 0.2123164\ttotal: 40.2s\tremaining: 26.8s\n",
      "30:\tlearn: 0.2112907\ttotal: 41.4s\tremaining: 25.4s\n",
      "31:\tlearn: 0.2104250\ttotal: 42.6s\tremaining: 24s\n",
      "32:\tlearn: 0.2090246\ttotal: 43.9s\tremaining: 22.6s\n",
      "33:\tlearn: 0.2079327\ttotal: 45s\tremaining: 21.2s\n",
      "34:\tlearn: 0.2065899\ttotal: 46.2s\tremaining: 19.8s\n",
      "35:\tlearn: 0.2057348\ttotal: 47.4s\tremaining: 18.4s\n",
      "36:\tlearn: 0.2046940\ttotal: 48.6s\tremaining: 17.1s\n",
      "37:\tlearn: 0.2038636\ttotal: 49.8s\tremaining: 15.7s\n",
      "38:\tlearn: 0.2027520\ttotal: 50.9s\tremaining: 14.4s\n",
      "39:\tlearn: 0.2016962\ttotal: 52.3s\tremaining: 13.1s\n",
      "40:\tlearn: 0.2009587\ttotal: 53.7s\tremaining: 11.8s\n",
      "41:\tlearn: 0.1999831\ttotal: 55.7s\tremaining: 10.6s\n",
      "42:\tlearn: 0.1991280\ttotal: 57.2s\tremaining: 9.31s\n",
      "43:\tlearn: 0.1983013\ttotal: 58.4s\tremaining: 7.96s\n",
      "44:\tlearn: 0.1977279\ttotal: 59.8s\tremaining: 6.64s\n",
      "45:\tlearn: 0.1971460\ttotal: 1m 1s\tremaining: 5.35s\n",
      "46:\tlearn: 0.1962365\ttotal: 1m 2s\tremaining: 4.02s\n",
      "47:\tlearn: 0.1956126\ttotal: 1m 4s\tremaining: 2.69s\n",
      "48:\tlearn: 0.1946818\ttotal: 1m 5s\tremaining: 1.34s\n",
      "49:\tlearn: 0.1938736\ttotal: 1m 7s\tremaining: 0us\n",
      "0:\tlearn: 0.5939836\ttotal: 1.56s\tremaining: 1m 16s\n",
      "1:\tlearn: 0.5178443\ttotal: 2.89s\tremaining: 1m 9s\n",
      "2:\tlearn: 0.4573847\ttotal: 4.17s\tremaining: 1m 5s\n",
      "3:\tlearn: 0.4088504\ttotal: 5.59s\tremaining: 1m 4s\n",
      "4:\tlearn: 0.3726063\ttotal: 6.86s\tremaining: 1m 1s\n",
      "5:\tlearn: 0.3444204\ttotal: 8.15s\tremaining: 59.7s\n",
      "6:\tlearn: 0.3214071\ttotal: 9.28s\tremaining: 57s\n",
      "7:\tlearn: 0.3036412\ttotal: 10.6s\tremaining: 55.5s\n",
      "8:\tlearn: 0.2891595\ttotal: 11.9s\tremaining: 54.2s\n",
      "9:\tlearn: 0.2776881\ttotal: 13.2s\tremaining: 52.7s\n",
      "10:\tlearn: 0.2684801\ttotal: 14.4s\tremaining: 51.1s\n",
      "11:\tlearn: 0.2611352\ttotal: 15.8s\tremaining: 50s\n",
      "12:\tlearn: 0.2544840\ttotal: 17s\tremaining: 48.3s\n",
      "13:\tlearn: 0.2489512\ttotal: 18.2s\tremaining: 46.8s\n",
      "14:\tlearn: 0.2441864\ttotal: 19.5s\tremaining: 45.4s\n",
      "15:\tlearn: 0.2391850\ttotal: 21s\tremaining: 44.6s\n",
      "16:\tlearn: 0.2356091\ttotal: 22.4s\tremaining: 43.5s\n",
      "17:\tlearn: 0.2322244\ttotal: 23.6s\tremaining: 42s\n",
      "18:\tlearn: 0.2297320\ttotal: 24.9s\tremaining: 40.6s\n",
      "19:\tlearn: 0.2276983\ttotal: 26.2s\tremaining: 39.3s\n",
      "20:\tlearn: 0.2257547\ttotal: 27.3s\tremaining: 37.8s\n",
      "21:\tlearn: 0.2233678\ttotal: 28.7s\tremaining: 36.6s\n",
      "22:\tlearn: 0.2215249\ttotal: 30s\tremaining: 35.2s\n",
      "23:\tlearn: 0.2194561\ttotal: 31.2s\tremaining: 33.9s\n",
      "24:\tlearn: 0.2178130\ttotal: 32.5s\tremaining: 32.5s\n",
      "25:\tlearn: 0.2163819\ttotal: 33.6s\tremaining: 31.1s\n",
      "26:\tlearn: 0.2149691\ttotal: 34.8s\tremaining: 29.6s\n",
      "27:\tlearn: 0.2137514\ttotal: 36s\tremaining: 28.3s\n",
      "28:\tlearn: 0.2124931\ttotal: 37.2s\tremaining: 26.9s\n",
      "29:\tlearn: 0.2113273\ttotal: 38.3s\tremaining: 25.6s\n",
      "30:\tlearn: 0.2103289\ttotal: 39.5s\tremaining: 24.2s\n",
      "31:\tlearn: 0.2089129\ttotal: 40.8s\tremaining: 22.9s\n",
      "32:\tlearn: 0.2078012\ttotal: 42s\tremaining: 21.6s\n",
      "33:\tlearn: 0.2068137\ttotal: 43.1s\tremaining: 20.3s\n",
      "34:\tlearn: 0.2055371\ttotal: 44.4s\tremaining: 19s\n",
      "35:\tlearn: 0.2044381\ttotal: 45.8s\tremaining: 17.8s\n",
      "36:\tlearn: 0.2034965\ttotal: 47s\tremaining: 16.5s\n",
      "37:\tlearn: 0.2026247\ttotal: 48.1s\tremaining: 15.2s\n",
      "38:\tlearn: 0.2018033\ttotal: 49.5s\tremaining: 14s\n",
      "39:\tlearn: 0.2010377\ttotal: 50.7s\tremaining: 12.7s\n",
      "40:\tlearn: 0.2000095\ttotal: 52.3s\tremaining: 11.5s\n",
      "41:\tlearn: 0.1992916\ttotal: 53.6s\tremaining: 10.2s\n",
      "42:\tlearn: 0.1982344\ttotal: 55.1s\tremaining: 8.97s\n",
      "43:\tlearn: 0.1976063\ttotal: 56.4s\tremaining: 7.69s\n",
      "44:\tlearn: 0.1970349\ttotal: 57.6s\tremaining: 6.4s\n",
      "45:\tlearn: 0.1958638\ttotal: 58.9s\tremaining: 5.12s\n",
      "46:\tlearn: 0.1952472\ttotal: 1m\tremaining: 3.85s\n",
      "47:\tlearn: 0.1946637\ttotal: 1m 1s\tremaining: 2.56s\n",
      "48:\tlearn: 0.1938315\ttotal: 1m 2s\tremaining: 1.28s\n",
      "49:\tlearn: 0.1929983\ttotal: 1m 3s\tremaining: 0us\n",
      "0:\tlearn: 0.5910856\ttotal: 1.57s\tremaining: 1m 16s\n",
      "1:\tlearn: 0.5138485\ttotal: 2.76s\tremaining: 1m 6s\n",
      "2:\tlearn: 0.4521931\ttotal: 4.01s\tremaining: 1m 2s\n",
      "3:\tlearn: 0.4069135\ttotal: 5.18s\tremaining: 59.6s\n",
      "4:\tlearn: 0.3710360\ttotal: 6.34s\tremaining: 57.1s\n",
      "5:\tlearn: 0.3422023\ttotal: 7.5s\tremaining: 55s\n",
      "6:\tlearn: 0.3194141\ttotal: 8.72s\tremaining: 53.6s\n",
      "7:\tlearn: 0.3008577\ttotal: 9.84s\tremaining: 51.7s\n",
      "8:\tlearn: 0.2869740\ttotal: 11s\tremaining: 50s\n",
      "9:\tlearn: 0.2754630\ttotal: 12.2s\tremaining: 48.7s\n",
      "10:\tlearn: 0.2664513\ttotal: 13.3s\tremaining: 47.2s\n",
      "11:\tlearn: 0.2589406\ttotal: 14.5s\tremaining: 46s\n",
      "12:\tlearn: 0.2523781\ttotal: 15.7s\tremaining: 44.7s\n",
      "13:\tlearn: 0.2470116\ttotal: 16.8s\tremaining: 43.3s\n",
      "14:\tlearn: 0.2416098\ttotal: 18s\tremaining: 42s\n",
      "15:\tlearn: 0.2379520\ttotal: 19.2s\tremaining: 40.9s\n",
      "16:\tlearn: 0.2338175\ttotal: 20.6s\tremaining: 39.9s\n",
      "17:\tlearn: 0.2310902\ttotal: 22s\tremaining: 39.1s\n",
      "18:\tlearn: 0.2284572\ttotal: 23.4s\tremaining: 38.2s\n",
      "19:\tlearn: 0.2261596\ttotal: 25s\tremaining: 37.5s\n",
      "20:\tlearn: 0.2238980\ttotal: 26.3s\tremaining: 36.4s\n",
      "21:\tlearn: 0.2220798\ttotal: 27.6s\tremaining: 35.1s\n",
      "22:\tlearn: 0.2201662\ttotal: 28.7s\tremaining: 33.7s\n",
      "23:\tlearn: 0.2184392\ttotal: 30s\tremaining: 32.5s\n",
      "24:\tlearn: 0.2169317\ttotal: 31.6s\tremaining: 31.6s\n",
      "25:\tlearn: 0.2156026\ttotal: 33.3s\tremaining: 30.8s\n",
      "26:\tlearn: 0.2141488\ttotal: 35s\tremaining: 29.8s\n",
      "27:\tlearn: 0.2129619\ttotal: 36.4s\tremaining: 28.6s\n",
      "28:\tlearn: 0.2117438\ttotal: 37.6s\tremaining: 27.3s\n",
      "29:\tlearn: 0.2104989\ttotal: 38.9s\tremaining: 25.9s\n",
      "30:\tlearn: 0.2095707\ttotal: 40.3s\tremaining: 24.7s\n",
      "31:\tlearn: 0.2085333\ttotal: 41.5s\tremaining: 23.3s\n",
      "32:\tlearn: 0.2071449\ttotal: 42.9s\tremaining: 22.1s\n",
      "33:\tlearn: 0.2063798\ttotal: 44.3s\tremaining: 20.8s\n",
      "34:\tlearn: 0.2052358\ttotal: 45.5s\tremaining: 19.5s\n",
      "35:\tlearn: 0.2042406\ttotal: 46.7s\tremaining: 18.2s\n",
      "36:\tlearn: 0.2030448\ttotal: 48.3s\tremaining: 17s\n",
      "37:\tlearn: 0.2022193\ttotal: 49.7s\tremaining: 15.7s\n",
      "38:\tlearn: 0.2015543\ttotal: 50.9s\tremaining: 14.4s\n",
      "39:\tlearn: 0.2007128\ttotal: 52.2s\tremaining: 13s\n",
      "40:\tlearn: 0.1999233\ttotal: 53.4s\tremaining: 11.7s\n",
      "41:\tlearn: 0.1989998\ttotal: 54.6s\tremaining: 10.4s\n",
      "42:\tlearn: 0.1979193\ttotal: 55.7s\tremaining: 9.07s\n",
      "43:\tlearn: 0.1973571\ttotal: 56.9s\tremaining: 7.75s\n",
      "44:\tlearn: 0.1967339\ttotal: 58s\tremaining: 6.45s\n",
      "45:\tlearn: 0.1960520\ttotal: 59.2s\tremaining: 5.14s\n",
      "46:\tlearn: 0.1950065\ttotal: 1m\tremaining: 3.85s\n",
      "47:\tlearn: 0.1943777\ttotal: 1m 1s\tremaining: 2.56s\n",
      "48:\tlearn: 0.1937919\ttotal: 1m 2s\tremaining: 1.28s\n",
      "49:\tlearn: 0.1930533\ttotal: 1m 3s\tremaining: 0us\n",
      "0:\tlearn: 0.5934452\ttotal: 3.11s\tremaining: 2m 32s\n",
      "1:\tlearn: 0.5140012\ttotal: 5.94s\tremaining: 2m 22s\n",
      "2:\tlearn: 0.4555788\ttotal: 7.43s\tremaining: 1m 56s\n",
      "3:\tlearn: 0.4093908\ttotal: 8.75s\tremaining: 1m 40s\n",
      "4:\tlearn: 0.3723522\ttotal: 9.95s\tremaining: 1m 29s\n",
      "5:\tlearn: 0.3447462\ttotal: 11.1s\tremaining: 1m 21s\n",
      "6:\tlearn: 0.3215363\ttotal: 12.2s\tremaining: 1m 15s\n",
      "7:\tlearn: 0.3032633\ttotal: 13.4s\tremaining: 1m 10s\n",
      "8:\tlearn: 0.2897936\ttotal: 14.8s\tremaining: 1m 7s\n",
      "9:\tlearn: 0.2785418\ttotal: 16.2s\tremaining: 1m 4s\n",
      "10:\tlearn: 0.2692850\ttotal: 17.5s\tremaining: 1m 2s\n",
      "11:\tlearn: 0.2604124\ttotal: 18.8s\tremaining: 59.5s\n",
      "12:\tlearn: 0.2535130\ttotal: 20s\tremaining: 57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:\tlearn: 0.2479260\ttotal: 21.2s\tremaining: 54.6s\n",
      "14:\tlearn: 0.2434892\ttotal: 22.4s\tremaining: 52.3s\n",
      "15:\tlearn: 0.2389627\ttotal: 23.7s\tremaining: 50.4s\n",
      "16:\tlearn: 0.2354247\ttotal: 25s\tremaining: 48.5s\n",
      "17:\tlearn: 0.2322560\ttotal: 26.1s\tremaining: 46.4s\n",
      "18:\tlearn: 0.2298084\ttotal: 27.2s\tremaining: 44.4s\n",
      "19:\tlearn: 0.2273066\ttotal: 28.4s\tremaining: 42.6s\n",
      "20:\tlearn: 0.2247383\ttotal: 29.8s\tremaining: 41.1s\n",
      "21:\tlearn: 0.2224923\ttotal: 31s\tremaining: 39.4s\n",
      "22:\tlearn: 0.2206985\ttotal: 32.2s\tremaining: 37.8s\n",
      "23:\tlearn: 0.2193029\ttotal: 33.4s\tremaining: 36.2s\n",
      "24:\tlearn: 0.2178802\ttotal: 34.6s\tremaining: 34.6s\n",
      "25:\tlearn: 0.2164012\ttotal: 35.9s\tremaining: 33.1s\n",
      "26:\tlearn: 0.2150215\ttotal: 37.1s\tremaining: 31.6s\n",
      "27:\tlearn: 0.2134995\ttotal: 38.2s\tremaining: 30s\n",
      "28:\tlearn: 0.2123366\ttotal: 39.4s\tremaining: 28.5s\n",
      "29:\tlearn: 0.2110873\ttotal: 40.8s\tremaining: 27.2s\n",
      "30:\tlearn: 0.2098515\ttotal: 42.1s\tremaining: 25.8s\n",
      "31:\tlearn: 0.2085974\ttotal: 43.3s\tremaining: 24.4s\n",
      "32:\tlearn: 0.2072060\ttotal: 44.5s\tremaining: 22.9s\n",
      "33:\tlearn: 0.2062933\ttotal: 45.8s\tremaining: 21.6s\n",
      "34:\tlearn: 0.2053640\ttotal: 47s\tremaining: 20.2s\n",
      "35:\tlearn: 0.2044588\ttotal: 48.3s\tremaining: 18.8s\n",
      "36:\tlearn: 0.2035270\ttotal: 49.5s\tremaining: 17.4s\n",
      "37:\tlearn: 0.2023689\ttotal: 50.8s\tremaining: 16.1s\n",
      "38:\tlearn: 0.2015756\ttotal: 52s\tremaining: 14.7s\n",
      "39:\tlearn: 0.2008248\ttotal: 53.3s\tremaining: 13.3s\n",
      "40:\tlearn: 0.1998764\ttotal: 54.6s\tremaining: 12s\n",
      "41:\tlearn: 0.1991665\ttotal: 56s\tremaining: 10.7s\n",
      "42:\tlearn: 0.1981731\ttotal: 57.3s\tremaining: 9.32s\n",
      "43:\tlearn: 0.1973625\ttotal: 58.6s\tremaining: 7.99s\n",
      "44:\tlearn: 0.1964189\ttotal: 59.7s\tremaining: 6.64s\n",
      "45:\tlearn: 0.1955156\ttotal: 1m\tremaining: 5.3s\n",
      "46:\tlearn: 0.1948926\ttotal: 1m 2s\tremaining: 3.97s\n",
      "47:\tlearn: 0.1942331\ttotal: 1m 3s\tremaining: 2.65s\n",
      "48:\tlearn: 0.1936727\ttotal: 1m 4s\tremaining: 1.32s\n",
      "49:\tlearn: 0.1931423\ttotal: 1m 6s\tremaining: 0us\n",
      "0:\tlearn: 0.5944687\ttotal: 1.87s\tremaining: 1m 31s\n",
      "1:\tlearn: 0.5144319\ttotal: 3.24s\tremaining: 1m 17s\n",
      "2:\tlearn: 0.4552655\ttotal: 4.66s\tremaining: 1m 12s\n",
      "3:\tlearn: 0.4081460\ttotal: 6.42s\tremaining: 1m 13s\n",
      "4:\tlearn: 0.3717025\ttotal: 7.71s\tremaining: 1m 9s\n",
      "5:\tlearn: 0.3420074\ttotal: 8.91s\tremaining: 1m 5s\n",
      "6:\tlearn: 0.3193090\ttotal: 10.3s\tremaining: 1m 3s\n",
      "7:\tlearn: 0.3016216\ttotal: 11.5s\tremaining: 1m\n",
      "8:\tlearn: 0.2872808\ttotal: 12.8s\tremaining: 58.4s\n",
      "9:\tlearn: 0.2763263\ttotal: 14.1s\tremaining: 56.4s\n",
      "10:\tlearn: 0.2662877\ttotal: 15.4s\tremaining: 54.8s\n",
      "11:\tlearn: 0.2587763\ttotal: 16.7s\tremaining: 53s\n",
      "12:\tlearn: 0.2528147\ttotal: 17.9s\tremaining: 51s\n",
      "13:\tlearn: 0.2475879\ttotal: 19.2s\tremaining: 49.4s\n",
      "14:\tlearn: 0.2429858\ttotal: 20.5s\tremaining: 47.9s\n",
      "15:\tlearn: 0.2392109\ttotal: 21.8s\tremaining: 46.4s\n",
      "16:\tlearn: 0.2360488\ttotal: 23.1s\tremaining: 44.9s\n",
      "17:\tlearn: 0.2325263\ttotal: 24.4s\tremaining: 43.4s\n",
      "18:\tlearn: 0.2295616\ttotal: 25.7s\tremaining: 41.9s\n",
      "19:\tlearn: 0.2269960\ttotal: 26.9s\tremaining: 40.3s\n",
      "20:\tlearn: 0.2249977\ttotal: 28.2s\tremaining: 39s\n",
      "21:\tlearn: 0.2232201\ttotal: 29.9s\tremaining: 38.1s\n",
      "22:\tlearn: 0.2213899\ttotal: 31.3s\tremaining: 36.7s\n",
      "23:\tlearn: 0.2198028\ttotal: 32.5s\tremaining: 35.2s\n",
      "24:\tlearn: 0.2184301\ttotal: 34s\tremaining: 34s\n",
      "25:\tlearn: 0.2169186\ttotal: 35.4s\tremaining: 32.7s\n",
      "26:\tlearn: 0.2153905\ttotal: 36.7s\tremaining: 31.3s\n",
      "27:\tlearn: 0.2142522\ttotal: 37.9s\tremaining: 29.8s\n",
      "28:\tlearn: 0.2131320\ttotal: 39.5s\tremaining: 28.6s\n",
      "29:\tlearn: 0.2116376\ttotal: 41s\tremaining: 27.3s\n",
      "30:\tlearn: 0.2104047\ttotal: 42.1s\tremaining: 25.8s\n",
      "31:\tlearn: 0.2093655\ttotal: 43.3s\tremaining: 24.3s\n",
      "32:\tlearn: 0.2083890\ttotal: 44.4s\tremaining: 22.9s\n",
      "33:\tlearn: 0.2075868\ttotal: 45.6s\tremaining: 21.5s\n",
      "34:\tlearn: 0.2060198\ttotal: 46.9s\tremaining: 20.1s\n",
      "35:\tlearn: 0.2049936\ttotal: 48.2s\tremaining: 18.8s\n",
      "36:\tlearn: 0.2042034\ttotal: 49.5s\tremaining: 17.4s\n",
      "37:\tlearn: 0.2032742\ttotal: 50.8s\tremaining: 16s\n",
      "38:\tlearn: 0.2024135\ttotal: 52s\tremaining: 14.7s\n",
      "39:\tlearn: 0.2012147\ttotal: 53.2s\tremaining: 13.3s\n",
      "40:\tlearn: 0.2005522\ttotal: 54.4s\tremaining: 11.9s\n",
      "41:\tlearn: 0.1998136\ttotal: 55.5s\tremaining: 10.6s\n",
      "42:\tlearn: 0.1990098\ttotal: 56.9s\tremaining: 9.26s\n",
      "43:\tlearn: 0.1982283\ttotal: 58.1s\tremaining: 7.93s\n",
      "44:\tlearn: 0.1975237\ttotal: 59.5s\tremaining: 6.61s\n",
      "45:\tlearn: 0.1967081\ttotal: 1m\tremaining: 5.3s\n",
      "46:\tlearn: 0.1957608\ttotal: 1m 2s\tremaining: 3.98s\n",
      "47:\tlearn: 0.1949267\ttotal: 1m 3s\tremaining: 2.65s\n",
      "48:\tlearn: 0.1943644\ttotal: 1m 4s\tremaining: 1.32s\n",
      "49:\tlearn: 0.1937946\ttotal: 1m 6s\tremaining: 0us\n",
      "0:\tlearn: 0.4426748\ttotal: 1.59s\tremaining: 1m 18s\n",
      "1:\tlearn: 0.3322189\ttotal: 3.09s\tremaining: 1m 14s\n",
      "2:\tlearn: 0.2800852\ttotal: 4.4s\tremaining: 1m 8s\n",
      "3:\tlearn: 0.2531777\ttotal: 5.8s\tremaining: 1m 6s\n",
      "4:\tlearn: 0.2393953\ttotal: 7.18s\tremaining: 1m 4s\n",
      "5:\tlearn: 0.2310106\ttotal: 8.54s\tremaining: 1m 2s\n",
      "6:\tlearn: 0.2224670\ttotal: 9.88s\tremaining: 1m\n",
      "7:\tlearn: 0.2175371\ttotal: 11.2s\tremaining: 58.7s\n",
      "8:\tlearn: 0.2136855\ttotal: 12.5s\tremaining: 57s\n",
      "9:\tlearn: 0.2105963\ttotal: 13.8s\tremaining: 55s\n",
      "10:\tlearn: 0.2069525\ttotal: 15s\tremaining: 53.1s\n",
      "11:\tlearn: 0.2035812\ttotal: 16.3s\tremaining: 51.6s\n",
      "12:\tlearn: 0.2009717\ttotal: 17.5s\tremaining: 49.7s\n",
      "13:\tlearn: 0.1978014\ttotal: 18.7s\tremaining: 48.1s\n",
      "14:\tlearn: 0.1953526\ttotal: 20.1s\tremaining: 46.8s\n",
      "15:\tlearn: 0.1929092\ttotal: 21.8s\tremaining: 46.3s\n"
     ]
    }
   ],
   "source": [
    "# initiatint the model\n",
    "catboost = CatBoostClassifier(random_seed=5,\n",
    "                              loss_function='Logloss')\n",
    "\n",
    "# preparing parameters to ask GridSearch, which contains cross validation\n",
    "parameters_cat = {'iterations':[50], \n",
    "                  'learning_rate': np.arange(0.1,1,0.2)}\n",
    "\n",
    "gsearch_catboost = GridSearchCV(catboost, \n",
    "                                param_grid=parameters_cat,\n",
    "                                verbose=False)\n",
    "\n",
    "gsearch_catboost.fit(tf_idf_X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b7d6ad",
   "metadata": {},
   "source": [
    "### 2.4 Gradient Boosting в модели \"мешка слова\" в классе TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3961ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2539fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89edf8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_LGBMClassifier = {    \n",
    "    \n",
    "    'n_estimators': [50, 100], \n",
    "    'learning_rate': [0.05, 0.1], \n",
    "    'verbose' : [-1],\n",
    "#     'boosting_type' : ['gbdt'],\n",
    "#     'num_leaves': [100],\n",
    "    'max_depth' : [-1],\n",
    "#     'min_split_gain' : [0.0],\n",
    "#     'min_child_samples' : [20],\n",
    "#     'subsample' : [1.0],\n",
    "#     'subsample_freq' : [0],\n",
    "#     'colsample_bytree': [1.0],\n",
    "#     'reg_alpha' : [0.0],\n",
    "#     'reg_lambda' : [0.0],\n",
    "#     'random_state' : [5],\n",
    "#     'silent' : [True]\n",
    "}\n",
    "\n",
    "LGBMClassifier_gsearch = GridSearchCV(estimator=model, \n",
    "                                     cv=3, \n",
    "                                     param_grid=params_LGBMClassifier)\n",
    "\n",
    "LGBMClassifier_gsearch.fit(tf_idf_X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c53ef8a",
   "metadata": {},
   "source": [
    "### 2.5 Сравним модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ae0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression CountVectorizer\n",
    "best_score_vect = round(logreg_grid.best_score_, 2)\n",
    "print(\"Best score Logistic Regression CountVectorizer: {:.2f}\".format(best_score_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e7ed7b78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score Logistic Regression (TF-IDF): 0.96\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF\n",
    "best_score_tfidf = round(grid.best_score_, 2)\n",
    "print('Best score Logistic Regression (TF-IDF): {:.2f}'.format(best_score_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a4ca4fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gsearch_catboost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# CatBoost\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_score_catboost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[43mgsearch_catboost\u001b[49m\u001b[38;5;241m.\u001b[39mbest_score_, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest score CatBoostClassifier (TF-IDF): \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_score_catboost))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gsearch_catboost' is not defined"
     ]
    }
   ],
   "source": [
    "# CatBoost\n",
    "best_score_catboost = round(gsearch_catboost.best_score_, 2)\n",
    "print('Best score CatBoostClassifier (TF-IDF): {}'.format(best_score_catboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "296d4065",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LGBMClassifier_gsearch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [175], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# LGBMRegressor\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_score_LGBM \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[43mLGBMClassifier_gsearch\u001b[49m\u001b[38;5;241m.\u001b[39mbest_score_, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest score LGBMClassifier (TF-IDF): \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_score_LGBM))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LGBMClassifier_gsearch' is not defined"
     ]
    }
   ],
   "source": [
    "# LGBMClassifier\n",
    "best_score_LGBM = round(LGBMClassifier_gsearch.best_score_, 2)\n",
    "print('Best score LGBMClassifier (TF-IDF): {}'.format(best_score_LGBM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0722bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the best score plot\n",
    "\n",
    "plt.rcParams.update({'font.size': 19, \n",
    "                     'text.color' : 'white', \n",
    "                     'axes.labelcolor' : \"blue\"})\n",
    "# plt.rcParams.update({'axes.titlesize': 'large'})\n",
    "fig, ax = plt.subplots(figsize=(19, 6))\n",
    "\n",
    "x = ['Logistic Regression (Count)', \n",
    "     'Logistic Regression (TF-IDF)', \n",
    "     'Cat Boost',\n",
    "    'Light GBM']\n",
    "y = [best_score_vect, \n",
    "     best_score_tfidf, \n",
    "     best_score_catboost,\n",
    "     best_score_LGBM]\n",
    "\n",
    "ax.bar(x, y, width=0.4, color='#008B8B')\n",
    "ax.set_title('best_score_ for each ML algorithm', fontsize=18)\n",
    "ax.set_xlabel('Regression Models', fontsize=18)\n",
    "ax.set_ylabel('best_score_', fontsize=18)\n",
    "ax.set_ylim(-45, 5)\n",
    "\n",
    "for index, value in enumerate(y):\n",
    "    plt.text(x=index, y=value + 0.05, s=str(value), ha='center')\n",
    "    \n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c548a",
   "metadata": {},
   "source": [
    "## 3 Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463829a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929322b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9278aa78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec4f4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fa02e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f66a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eebe9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c2f79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e682fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c8d357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cdf250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176a29fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11eb4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619e5cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8763aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341f78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df6f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12729fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6ac84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cdf589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f5f51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9232a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52f64d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4183af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b7fdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65938e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d104e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4155942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e08ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824e542f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf8fde8a",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4771856b",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3cbc41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
